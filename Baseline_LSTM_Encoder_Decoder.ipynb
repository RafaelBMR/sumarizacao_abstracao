{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import LSTM, Input, Embedding, Dense, TimeDistributed\n",
    "from keras.models import Model\n",
    "import pickle\n",
    "import numpy as np\n",
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_obj(name):\n",
    "    with open( name, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "def save_obj(obj, name):\n",
    "    with open(name, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def montar_sentenca(indices_sentenca):\n",
    "    indices = np.zeros((43), dtype=np.int16)\n",
    "    i = 0\n",
    "    while i < len(indices_sentenca):\n",
    "        indices[i] = indices_sentenca[i]\n",
    "        i += 1\n",
    "    return indices\n",
    "\n",
    "def montar_manchete(indices_manchetes):\n",
    "    indices_entrada = np.zeros((20), dtype=np.int16)\n",
    "    saidas = np.zeros((20, len(ind2token_manchetes)), dtype=np.int16)\n",
    "    i = 0\n",
    "    while i < len(indices_manchetes) - 1 and i < 20:\n",
    "        indices_entrada[i] = indices_manchetes[i]\n",
    "        saidas[i][indices_manchetes[i+1]] = 1\n",
    "        i += 1\n",
    "    return indices_entrada, saidas\n",
    "\n",
    "def montar_bloco(exemplos_batch):\n",
    "    sentencas_indices = []\n",
    "    manchetes_indices = []\n",
    "    saidas = []\n",
    "    for exemplo in exemplos_batch:\n",
    "        sentencas_indices.append(montar_sentenca(exemplo['indices_sentenca']))\n",
    "        indices_manchete, saida = montar_manchete(exemplo['indices_manchete'])\n",
    "        manchetes_indices.append(indices_manchete)\n",
    "        saidas.append(saida)\n",
    "    sentencas_indices = np.array(sentencas_indices, dtype=np.int16)\n",
    "    manchetes_indices = np.array(manchetes_indices, dtype=np.int16)\n",
    "    saidas = np.array(saidas)\n",
    "    return sentencas_indices, manchetes_indices, saidas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arquivos Necessários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ind2token_manchetes = load_obj(\"ind2token_manchetes.pkl\")\n",
    "token2ind_manchetes = load_obj(\"token2ind_manchetes.pkl\")\n",
    "ind2token_sentencas = load_obj(\"ind2token_sentencas.pkl\")\n",
    "token2ind_sentencas = load_obj(\"token2ind_sentencas.pkl\")\n",
    "ind2tag = load_obj(\"ind2tag.pkl\")\n",
    "tag2ind = load_obj(\"tag2ind.pkl\")\n",
    "representacoes_manchetes_100 = np.load(\"representacoes_manchetes_100.npy\")\n",
    "representacoes_sentencas_200 = np.load(\"representacoes_sentencas_200.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurações do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M = 43\n",
    "N = 20\n",
    "tamanho_embedding_sentenca = 200\n",
    "tamanho_embedding_manchete = 100\n",
    "E = representacoes_manchetes_100.copy()\n",
    "F = representacoes_sentencas_200.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# O modelo encoder-decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentenca_entrada = Input(shape=(M,))\n",
    "manchete_entrada = Input(shape=(N,))\n",
    "embeddings_sentenca = Embedding(len(ind2token_sentencas), tamanho_embedding_sentenca, weights=[F],\n",
    "                                trainable=True, mask_zero=True)(sentenca_entrada)\n",
    "embeddings_manchete = Embedding(len(ind2token_manchetes), tamanho_embedding_manchete, weights=[E], \n",
    "                               trainable=True, mask_zero=True)(manchete_entrada)\n",
    "\n",
    "# Codificador\n",
    "saidas_encoder, encoder_h, encoder_c = LSTM(200, return_state=True)(embeddings_sentenca)\n",
    "\n",
    "# Decodificador\n",
    "sequencia_gerada, _, _ = LSTM(200, return_sequences=True, return_state=True)(embeddings_manchete, \n",
    "                                                                             initial_state=[encoder_h, encoder_c])\n",
    "\n",
    "saidas = TimeDistributed(Dense(len(ind2token_manchetes), activation='softmax'))(sequencia_gerada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model([sentenca_entrada, manchete_entrada], saidas)\n",
    "model.compile('rmsprop', loss=\"categorical_crossentropy\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurações do treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 30\n",
    "batch_size = 16\n",
    "tamanhos_treinamento = list(range(23,44))\n",
    "losses_treinamento = []\n",
    "losses_validacao = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inicio = dt.now()\n",
    "for epoch in range(num_epochs):\n",
    "    # Embaralha os tamanhos\n",
    "    np.random.shuffle(tamanhos_treinamento)\n",
    "    # Carrega cada bloco e treina\n",
    "    losses_treinamento_epoch = []\n",
    "    print(\"Início do treino epoch \", str(epoch))\n",
    "    for tamanho in tamanhos_treinamento:\n",
    "        exemplos = load_obj(\"exemplos_treinamento_\" + str(tamanho) + \".pkl\")\n",
    "        sentencas, manchetes, saidas = montar_bloco(exemplos)\n",
    "        history = model.fit(x=[sentencas, manchetes], y=saidas, batch_size=batch_size, verbose=1)\n",
    "        losses_treinamento_epoch.append(history.history['loss'])\n",
    "        \n",
    "    loss_treinamento = np.mean(losses_treinamento_epoch)\n",
    "    losses_treinamento.append(loss_treinamento)\n",
    "    # Validação\n",
    "    losses_validacao_epoch = []\n",
    "    print(\"Início da validação epoch \", str(epoch))\n",
    "    for tamanho in tamanhos_treinamento:\n",
    "        exemplos_validacao = load_obj(\"exemplos_validacao_\" + str(tamanho) + \".pkl\")\n",
    "        sentencas, manchetes, saidas = montar_bloco(exemplos_validacao)\n",
    "        losses_validacao_epoch.append(model.evaluate(x=[sentencas, manchetes], y=saidas, verbose=1))\n",
    "    loss_validacao = np.mean(losses_validacao_epoch)\n",
    "    losses_validacao.append(loss_validacao)\n",
    "    print(\"Epoch \", str(epoch + 1), \". Loss treinamento: \", str(loss_treinamento), \". Loss validação: \", \n",
    "          str(loss_validacao), \"\\nTempo total: \", str(dt.now() - inicio))\n",
    "    model.save(\"salvar_baseline/model_baseline_com_embeddings_\" + str(epoch) + \".h5\")\n",
    "    model.save_weights(\"salvar_baseline/model_baseline_com_embeddings_so_pesos_\" + str(epoch) + \".h5\")\n",
    "    save_obj(losses_validacao, \"salvar_baseline/losses_validacao_\" + str(epoch) + \".pkl\")\n",
    "    save_obj(losses_treinamento, \"salvar_baseline/losses_treinamento_\" + str(epoch) + \".pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
